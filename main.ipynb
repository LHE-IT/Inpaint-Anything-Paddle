{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71c576e9-6ed9-4ba2-a932-18aa59654ef9",
   "metadata": {},
   "source": [
    "# Inpaint Anything——当SAM遇上图像修复\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da676a5-84de-4794-9bad-540d49185169",
   "metadata": {},
   "source": [
    "## 一、项目介绍\n",
    "\n",
    "该项目的趣味点在于可以结合分割大模型 SAM 进行图像编辑（对象移除、替换背景、前景等），从而生成各种十分有趣的图像，相较于 stable diffusion 方式， 这种图像生成方式更加稳定可靠，且后续通过叠加人体姿态估计、视频渲染等技术可以实现AI视频生成，比如：实现 Wonder Studio 的AI 视频特效。\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/0663b88dc43f466eb43e3bcfb5717fab37adb511697f46818cc265477f894eb8)\n",
    "\n",
    "该项目是对 官方 Inpaint Anything（pytorch） 的 paddle 实现， 采用分割大模型 Segment Anything（SAM）获得图像 mask，采用图像修复模型 LaMa 进行图像移除，并采用 stable_diffusion_inpaint 进行文本引导的图像编辑。用户可以通过图像中任意对象的点坐标，平滑地进行对象移除。此外，用户还可以通过文本提示，用任何内容填充对象，或任意替换对象的背景。同时，本人结合 PP-YOLOE 在COCO 数据集上的预训练模型，对图像级的 Remove Anything 进行扩展，实现了指定类别的视频目标移除（Remove Anything Video）。\n",
    "\n",
    "该项目可以在 V100 16G 环境下运行，项目的主要工作是对  LaMa 模型的推理部分及依赖库 kornia 部分函数进行复现， 并通过调用 PaddleSeg 的 Segment Anything（SAM）模型 和 PaddleNLP 的 Stable Diffusion Inpaint模型， 完成 Inpaint Anything 相应功能的实现。对于视频目标移除部分，该项目首先采用PP-YOLOE 检测视频中的所有目标，之后，将每帧图像中用户需要移除对象的边界框依次送入到 SAM 模型中，获得每个移除对象的 mask，并将所有对象mask汇总为最终 mask，送入到 LaMa 模型中，进行对象移除。\n",
    "\n",
    "该项目实现了 Inpaint Anything 中的 Remove Anything、Fill Anything 和 Replace Anything 三种图像编辑模式，并在 Remove Anything 基础上扩展出 Remove Anything Video 模式。 由于 paddle 的随机因子和 torch 不同，Fill Anything 和 Replace Anything 与官方项目的结果有所差异。\n",
    "\n",
    "下面是 Inpaint Anything 的一些有趣例子：\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/5d4feb226af44a7eb04663a92f2fddf3ea07d2ff1dcd4739b1643bf9c224762f)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8276f530-2dbb-469b-b414-5b6a192f6f61",
   "metadata": {},
   "source": [
    "## 二、详细说明   \n",
    "\n",
    "**创意来源** ：近期看到 Wonder Studio 的AI视频特效，被其合成的 CG 视频震撼到了，于是心血来潮，打算复刻一下低配版的 Wonder Studio 。根据官网网站，AI视频特效需要经过 Motion Capture（动作捕捉）、Character Pass（角色动作绑定）、Alpha Mask（Alpha遮罩）、Clean Plate（人物擦除）、Camera Track（相机跟踪）、Blender File（生成 Blender 文件）和 Final Render（视频渲染）七个部分。其中，动作捕捉部分可以采用 paddle 中的人体姿态估计方案，角色动作绑定、相机跟踪部分可以采用 Unity 或 UE4 图形学引擎解决， Blender 文件生成和视频渲染可以采用相关3d建模软件解决，但是一直没有找到合适的对象移除方案，来完成 Alpha Mask（Alpha遮罩）和 Clean Plate（目标移除）环节。Omnimatte 虽然可以将对象及对象所产生的效果一同移除，但是单个视频模型训练需要耗费2小时，且需要额外准备 光流文件和视频分割结果，因此性价比较低。偶然看到 Inpaint Anything 已经可以很好地进行图像移除了，于是对其中的LaMa进行了复现，并结合 paddle 的文本图像编辑模型，完成了 Inpaint Anything相关功能的实现。之后，本人结合 PP-YOLOE 检测模型，对图像级的 Remove Anything 进行了扩展，实现了指定类别的视频目标移除。\n",
    "\n",
    " **目前相关的项目**： 官方 Inpaint Anything 地址（pytorch）如下： [https://github.com/geekyutao/Inpaint-Anything](https://github.com/geekyutao/Inpaint-Anything)。 官方项目就是对已有的图像分割、图像修复、文本图像生成 SOTA 方法进行组装。与官方项目不同的是，该项目对LaMa 源码进行了精简，只保留推理部分，因此不再需要安装 LaMa 训练所需的诸多依赖。此外，同类的视频对象移除（隐身）项目还包括 Omnimatte，项目地址如下：[https://github.com/erikalu/omnimatte](https://github.com/erikalu/omnimatte)。\n",
    " \n",
    "  **技术细节**：Inpaint Anything 的项目架构图如下：首先，将待编辑图像及其点坐标输入到 Segment Anything中获得指定图像 mask，之后结合图像修复SOTA模型（如：LaMa、Repaint、MAT 和 ZITS）对指定对象进行移除，结合AIGG模型（如：扩散模型 stable diffusion 等）和文本提示，对指定图像或其所在的背景进行填充。下面将对项目的具体实现步骤进行阐述。由于代码块不会自动释放显存，项目模型显存占用率又比较高，必要时需要重启内核，释放显存。\n",
    "  \n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/6fd7213ca3b54182880b0a5fe6f195c854ca7bea0ab44bc5ab030b94b9cae316)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9de7c86-094f-4ab2-8d46-917e3514124f",
   "metadata": {},
   "source": [
    "### 2.1 环境配置\n",
    "\n",
    "由于该项目直接调用的 PaddleSeg 中的 SAM 模型和  PaddleNLP 的 stable_diffusion_inpaint模型，因此需要安装 PaddleSeg 、ppdiffusers 等相关库。此外，由于模型文件过大，两个模型加在一起约 6 G 左右，每次启动项目都要下载十分耗时，因此，这里将 SAM 模型、 stable_diffusion_inpaint 权重文件和视频目标移除的检测器 PP-YOLOE 权重文件 保存在 AI studio 数据集中，启动项目后直接拷贝到预设路径即可。由于命令行会将其权重文件解压到 AI Studio 本地路径，解压命令只需要在初次运行项目时运行一次即可，之后可以注释掉解压命令，每次只将权重拷贝到预定义路径即可。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3912ec25-1d01-4ba8-99c2-d97f68e924ad",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 安装 paddleseg,以便调用其中的SAM模型\n",
    "%cd /home/aistudio/\n",
    "!pip install paddleseg==2.8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12571e21-1587-46a5-b666-084bc13c5317",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 安装SAM模型的依赖包\n",
    "!pip install --user ftfy regex\n",
    "# 安装 pddiffuser，以便调用其中的paddlenlp 模型\n",
    "!pip install --user --upgrade ppdiffusers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddca7767-1e7d-41f0-aa96-5489253f5790",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 由于下载SAM模型时间较长，这里直接将其拷贝到 paddleseg要求的模型目录下\n",
    "%cd /home/aistudio/\n",
    "!mkdir .paddleseg\n",
    "!mkdir .paddleseg/pretrained_model\n",
    "!mkdir .paddleseg/pretrained_model/vit_l\n",
    "!cp /home/aistudio/data/data211468/vit_l_sam.pdparams /home/aistudio/.paddleseg/pretrained_model/vit_l/model.pdparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0b533c-287a-45f7-96c1-4e94b69d2fbb",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 由于 stable diffusion inpaint模型 下载时间过长，这里直接将其拷贝到 paddlenlp 要求的模型目录下\n",
    "# 这里只需要解压一次，之后可注释掉解压命令，直接拷贝即可\n",
    "# %cd /home/aistudio/\n",
    "# !unzip /home/aistudio/data/data211468/stable_diff_inpaint.zip\n",
    "!mkdir .cache\n",
    "!cp -r /home/aistudio/stable_diffusion_inpaint/paddlenlp /home/aistudio/.cache/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960df904-2307-43d7-96a0-64a44db97582",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 解压检测器模型，以便对视频中需要移除的目标进行检测\n",
    "%cd /home/aistudio/\n",
    "!unzip /home/aistudio/data/data211468/coco.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940d1f31-b01e-407e-9cda-91937af10fbc",
   "metadata": {},
   "source": [
    "### 2.2 加载SAM模型，并获取指定目标 mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9925a62-0c83-4903-b1e5-9923b7508e7a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 将当前路径切换为/home/aistudio/work/，以便导入LaMa代码中的相关函数\n",
    "%cd /home/aistudio/work/\n",
    "# 导入相关包\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "from PIL import Image \n",
    "from pathlib import Path\n",
    "import paddle\n",
    "import cv2\n",
    "import numpy as np\n",
    "os.path.join( \"/home/aistudio/work/..\")\n",
    "from segment_anything.predictor import SamPredictor\n",
    "from segment_anything.build_sam import sam_model_registry\n",
    "from lama_inpaint import inpaint_img_with_lama\n",
    "from utils import load_img_to_array, save_array_to_img, dilate_mask, \\\n",
    "    show_mask, show_points\n",
    "from matplotlib import pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import logging\n",
    "logging.disable(logging.WARNING)\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = '0' \n",
    "# SAM 模型不同版本下载地址\n",
    "model_link = {\n",
    "    'vit_h':\n",
    "    \"https://bj.bcebos.com/paddleseg/dygraph/paddlesegAnything/vit_h/model.pdparams\",\n",
    "    'vit_l':\n",
    "    \"https://bj.bcebos.com/paddleseg/dygraph/paddlesegAnything/vit_l/model.pdparams\",\n",
    "    'vit_b':\n",
    "    \"https://bj.bcebos.com/paddleseg/dygraph/paddlesegAnything/vit_b/model.pdparams\"\n",
    "}\n",
    "input_path =\"/home/aistudio/work/example/remove-anything/sample1.png\"\n",
    "sam_model_type = \"vit_l\"\n",
    "point = np.array([[750, 500]])\n",
    "point_labels=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40bf789-7ace-4b7f-be32-aaf9a2ef1949",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 读取输入图片\n",
    "img  = cv2.imread(input_path)\n",
    "img  = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "# 加载SAM模型\n",
    "model = sam_model_registry[sam_model_type](\n",
    "checkpoint=model_link[sam_model_type])\n",
    "# 调用Sam模型进行图像mask推理，可以采用 box或 point 提示，简单起见，这里输入待分割目标point（x，y）\n",
    "predictor = SamPredictor(model)\n",
    "predictor.set_image(img)\n",
    "masks, _, _ = predictor.predict(\n",
    "        point_coords=point,\n",
    "        point_labels=point_labels,\n",
    "        box=None,\n",
    "        multimask_output=True, )\n",
    "masks = masks.astype(np.uint8) * 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d84fe4-f164-4861-ae82-a7bc0b7fb646",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# mask 可视化\n",
    "for idx, mask in enumerate(masks):\n",
    "    dpi = plt.rcParams['figure.dpi']\n",
    "    height, width = img.shape[:2]\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    show_mask(plt.gca(), mask, random_color=False)\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767377d4-4788-42ee-86c7-693b33a52b27",
   "metadata": {},
   "source": [
    "### 2.3 利用mask，实现图像对象移除（Remove Anything）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca0e291-84bd-4c04-8ce0-304ef73a81d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import paddle\n",
    "import yaml\n",
    "import glob\n",
    "import argparse\n",
    "from PIL import Image\n",
    "from omegaconf import OmegaConf\n",
    "from saicinpainting.training.modules import make_generator\n",
    "import paddle.nn.functional as F\n",
    "from lama_inpaint import pad_tensor_to_modulo\n",
    "# 利用LaMa 进行目标移除\n",
    "def inpaint_img_with_lama(\n",
    "        img: np.ndarray,\n",
    "        mask: np.ndarray,\n",
    "        config_p: str,\n",
    "        ckpt_p: str,\n",
    "        predict_config: str=\"./lama/configs/prediction/default.yaml\",\n",
    "        mod=8,\n",
    "):\n",
    "    assert len(mask.shape) == 2\n",
    "    # 图像和mask预处理\n",
    "    if np.max(mask) == 1:\n",
    "        mask = mask * 255\n",
    "    img = paddle.to_tensor(img/255.0,dtype='float32')\n",
    "    mask = paddle.to_tensor(mask,dtype=\"float32\")\n",
    "    # 加载推理配置文件\n",
    "    predict_config = OmegaConf.load(predict_config)\n",
    "    predict_config.model.path = ckpt_p\n",
    "    # 加载模型配置文件\n",
    "    with open(config_p, 'r') as f:\n",
    "        train_config = OmegaConf.create(yaml.safe_load(f))\n",
    "\n",
    "    train_config.training_model.predict_only = True\n",
    "    train_config.visualizer.kind = 'noop'\n",
    "    # 构建模型并加载相应权重     \n",
    "    model = make_generator(train_config, **train_config.generator)\n",
    "    path = ckpt_p\n",
    "    state = paddle.load(path)\n",
    "    model.set_state_dict(state)\n",
    "    model.eval()\n",
    "   # 创建batch字典,作为模型输入\n",
    "    batch = {}\n",
    "    batch['image'] = img.transpose([2, 0, 1]).unsqueeze(0)\n",
    "    batch['mask'] = mask[None, None]\n",
    "    unpad_to_size = [batch['image'].shape[2], batch['image'].shape[3]]\n",
    "    batch['image'] = pad_tensor_to_modulo(batch['image'], mod)\n",
    "    batch['mask'] = pad_tensor_to_modulo(batch['mask'], mod)\n",
    "    batch['mask'] = (batch['mask'] > 0).cast('float32')\n",
    "\n",
    "    img = batch['image']\n",
    "    mask = batch['mask']\n",
    "    img = paddle.to_tensor(img) \n",
    "    mask = paddle.to_tensor(mask)  \n",
    "    masked_img = img * (1 - mask)\n",
    "    masked_img = paddle.concat([masked_img, mask], axis =1)\n",
    "   # 预测图像修复结果 \n",
    "    with paddle.no_grad():\n",
    "        batch['predicted_image'] = model(masked_img)\n",
    "    batch['inpainted'] = mask * batch['predicted_image'] + (1 - mask) * batch['image']\n",
    "    # 根据预设键值，获取修复后的图像\n",
    "    cur_res = batch[predict_config.out_key][0].transpose([1, 2, 0])\n",
    "    cur_res = cur_res.detach().cpu().numpy()\n",
    "     #对修复结果进行后处理\n",
    "    if unpad_to_size is not None:\n",
    "        orig_height, orig_width = unpad_to_size\n",
    "        cur_res = cur_res[:orig_height, :orig_width]\n",
    "   \n",
    "    cur_res = np.clip(cur_res * 255, 0, 255).astype('uint8')\n",
    "    return cur_res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b8d196-de9d-4653-b313-403c81e2f939",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "lama_config=\"/home/aistudio/work/lamn/big_lanm/config.yaml\"\n",
    "lama_ckpt=\"/home/aistudio/data/data211468/paddle_gen.pdparams\"\n",
    "predict_config=\"/home/aistudio/work/lamn/config/default.yml\"\n",
    "dilate_kernel_size = 15\n",
    "# 对mask 进行膨胀操作，此步十分重要，否则由于没有目标周围纹理作为参考，图像修复效果会变得极差。\n",
    "masks1 = [dilate_mask(mask, dilate_kernel_size) for mask in masks]\n",
    "# 移除后的图像可视化\n",
    "for idx, mask in enumerate(masks1):\n",
    "    img_inpainted = inpaint_img_with_lama(\n",
    "        img, mask, lama_config, lama_ckpt, predict_config)\n",
    "    plt.imshow(img_inpainted)\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bec2b71-9024-4be6-af30-ce548c2a32d4",
   "metadata": {},
   "source": [
    "### 2.4 结合 PP-YOLOE，实现视频对象移除（Remove Anything Video）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcee5ed-2095-4f6e-8f52-34909bfc7029",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%cd /home/aistudio/work/\n",
    "from tqdm import tqdm\n",
    "from remove_anything_video import label_list,save_videos_grid, process_yoloe,array_to_img\n",
    "# 设置视频路径和移除对象类别\n",
    "input_path = \"/home/aistudio/work/example/remove-anything-video/car.mp4\"\n",
    "remove_type =  [\"car\"]\n",
    "# 设置输出路径和配置文件路径\n",
    "output_dir=\"/home/aistudio/work/results\"\n",
    "lama_config=\"/home/aistudio/work/lamn/big_lanm/config.yaml\"\n",
    "lama_ckpt=\"/home/aistudio/data/data211468/paddle_gen.pdparams\"\n",
    "predict_config=\"/home/aistudio/work/lamn/config/default.yml\"\n",
    "dilate_kernel_size = 15\n",
    "src_video_dir =  input_path \n",
    "# 读取视频\n",
    "video_object = cv2.VideoCapture(src_video_dir)\n",
    "fps = video_object.get(cv2.CAP_PROP_FPS)\n",
    "frame_paths_list = []\n",
    "# 加载检测器模型\n",
    "detector = paddle.jit.load('/home/aistudio/ppyoloe_plus_crn_l_80e_coco/model')\n",
    "detector.eval()\n",
    "# 获取视频总帧数，并设置进度条\n",
    "frame_count = int(video_object.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "progress_bar = tqdm(total=frame_count)\n",
    "# 由于检测器在COCO数据训练，检测不出COCO 80类外的类别，如果需要移除的类别不在COCO 80类中,程序会报错\n",
    "for item in  remove_type:\n",
    "    if item not in label_list:\n",
    "        raise ValueError('the remove object type is not in COCO 80 class ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aee881c-0164-4a6c-8d53-db09351b5254",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 根据用户指定类别对检测器中的边界框进行筛选\r\n",
    "def select_desired_box(pre,remove_type):\r\n",
    "    box = []\r\n",
    "    maxS = 0\r\n",
    "    box = []\r\n",
    "    max_item = None\r\n",
    "    # 遍历检测结果\r\n",
    "    for item in pre[0].numpy(): \r\n",
    "        cls, value, xmin, ymin, xmax, ymax = list(item)\r\n",
    "        cls, xmin, ymin, xmax, ymax = [int(x) for x in [cls, xmin, ymin, xmax, ymax]]\r\n",
    "        curS = (ymax-ymin)*(xmax-xmin)\r\n",
    "        label = label_list[cls]\r\n",
    "        # 对于非\"person\"的其他类别,如果边界框类别包含在指定类别中,则将其加入到最终box列表中\r\n",
    "        if value>0.5 and label!=\"person\" and (label in remove_type):\r\n",
    "            box.append( np.array([[xmin, ymin], [xmax, ymax]]))\r\n",
    "        # 对于\"person\"类别,如果\"person\"类别包含在指定类别中,则将面积最大的检测框加入到box中\r\n",
    "        if value>0.5 and label==\"person\" and (label in remove_type):\r\n",
    "            if curS>maxS:\r\n",
    "                maxS=curS\r\n",
    "                max_item = item\r\n",
    "    # 判断\"person\"类别的最大检测框是否存在,若存在,加入到box列表中\r\n",
    "    if max_item is not None:\r\n",
    "        cls, value, xmin, ymin, xmax, ymax = list( max_item )\r\n",
    "        box.append( np.array([[xmin, ymin], [xmax, ymax]]))\r\n",
    "    return box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d160b32d-7ae1-479e-a379-ff261c61409b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 遍历视频\r\n",
    "while True:\r\n",
    "    ret, frame = video_object.read()\r\n",
    "    # 已经是最后一帧,则退出\r\n",
    "    if ret == False:\r\n",
    "        print(\"predict_rbox_frame_from_video({})\".format(src_video_dir))\r\n",
    "        break\r\n",
    "    frame = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)      \r\n",
    "    im_info = {\r\n",
    "        'scale_factor': np.array(\r\n",
    "            [1., 1.], dtype=np.float32),\r\n",
    "        'im_shape': None}\r\n",
    "    h1, w1 = frame.shape[:-1]\r\n",
    "    #进行图像预处理,以便后续检测器进行检测 \r\n",
    "    im, im_shape, factor = process_yoloe(frame, im_info, [640, 640])\r\n",
    "    # 使用 PP-YOLOE 对图像中所有目标进行检测\r\n",
    "    with paddle.no_grad():\r\n",
    "        pre = detector(im, factor)\r\n",
    "    # 筛选出位于移除类别列表中的检测框\r\n",
    "    box = select_desired_box(pre,remove_type)\r\n",
    "    if len(box)>0:\r\n",
    "        # 初始化一张值全为0的mask\r\n",
    "        init_mask = np.zeros([h1,w1])\r\n",
    "        for b in box:\r\n",
    "            # 采用SAM获取边界框所对应的 mask\r\n",
    "            predictor = SamPredictor(model)\r\n",
    "            predictor.set_image(frame)\r\n",
    "            masks1, _, _ = predictor.predict(\r\n",
    "            point_coords=None,\r\n",
    "            point_labels=1,\r\n",
    "            box=b,\r\n",
    "            multimask_output=True, )\r\n",
    "            masks1 = masks1.astype(np.uint8) * 255\r\n",
    "            # 对mask进行膨胀处理\r\n",
    "            if dilate_kernel_size is not None:\r\n",
    "                masks1 = [dilate_mask(mask, dilate_kernel_size) for mask in masks1]\r\n",
    "            # 将当前边界框mask融合到初始化mask中 \r\n",
    "            idx = np.array(masks1[0]==255)\r\n",
    "            init_mask[idx]=255\r\n",
    "        # 将包含所有需要移除目标mask的初始化mask送入到LaMa中进行目标移除\r\n",
    "        img_inpainted = inpaint_img_with_lama(\r\n",
    "            frame,  init_mask, lama_config, lama_ckpt, predict_config)\r\n",
    "        img_inpainted = array_to_img(img_inpainted)\r\n",
    "\r\n",
    "        frame_remove  = np.array(img_inpainted)\r\n",
    "        frame_remove = cv2.resize( frame_remove,dsize=None, fx=0.4, fy= 0.4 )\r\n",
    "        orginal_frame = cv2.resize( frame,dsize=None, fx=0.4, fy= 0.4)\r\n",
    "        # 将原始帧和移除后帧拼接,并加入到 frame_paths_list 列表中\r\n",
    "        concat_frame = np.hstack(( orginal_frame,frame_remove))\r\n",
    "        frame_remove = paddle.to_tensor(concat_frame /255.0, dtype='float32').unsqueeze(0)\r\n",
    "        frame_paths_list.append( frame_remove)\r\n",
    "    # break\r\n",
    "    progress_bar.update(1)\r\n",
    "# 创建输出目录\r\n",
    "video_seq = paddle.concat(frame_paths_list, axis= 0)\r\n",
    "video_seq = paddle.to_tensor(video_seq).transpose([3, 0, 1, 2 ]).unsqueeze(0)\r\n",
    "img_stem = Path( input_path).stem\r\n",
    "out_dir = Path(output_dir) / img_stem\r\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\r\n",
    "# 将原始视频和移除后的视频保存为GIF\r\n",
    "git_img_p =\"{}/ {}\".format(out_dir,os.path.basename(input_path).replace(\".mp4\",\".gif\"))\r\n",
    "save_videos_grid(video_seq,    git_img_p,fps=fps )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae2b782-d7b6-43f6-a954-e604339413af",
   "metadata": {},
   "source": [
    "视频移除完成后，可以在 /home/aistudio/work/results/car/ 路径下点击 car.gif 图像，在AI Studio中 查看移除视频的效果。具体效果如下:\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/d90cfffc711049b698273b56c1e4215ef2653594566c4be996ddd5387e5ff290)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35a8139-0835-4b42-b847-e55ef96e47ef",
   "metadata": {},
   "source": [
    "### 2.5 利用mask，实现对象填充（Fill Anything）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd3396e-0af3-4de0-94fd-675fa7339e58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from utils.mask_processing import crop_for_filling_pre, crop_for_filling_post\n",
    "from utils.crop_for_replacing import recover_size, resize_and_pad\n",
    "from ppdiffusers import StableDiffusionInpaintPipeline\n",
    "# 利用 StableDiffusionInpaint 实现对象填充\n",
    "def fill_img_with_sd(\n",
    "        img: np.ndarray,\n",
    "        mask: np.ndarray,\n",
    "        text_prompt: str,\n",
    "):\n",
    "    # 加载 StableDiffusionInpaint 模型\n",
    "    pipe = StableDiffusionInpaintPipeline.from_pretrained(\"stabilityai/stable-diffusion-2-inpainting\")\n",
    "    # 对 img 和 mask进行预处理（缩放、填充、裁剪）\n",
    "    img_crop, mask_crop = crop_for_filling_pre(img, mask)\n",
    "    # 生成填充后的图像\n",
    "    img_crop_filled = pipe(\n",
    "        prompt=text_prompt,\n",
    "        image=Image.fromarray(img_crop),\n",
    "        mask_image=Image.fromarray(mask_crop)\n",
    "    ).images[0]\n",
    "    # 对填充后的图像进行后处理（将合成的前景图像填充回原图像中）\n",
    "    img_filled = crop_for_filling_post(img, mask, np.array(img_crop_filled))\n",
    "    return img_filled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1f2e91-4006-4c57-8d87-a96721d0c4cc",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 对mask 进行膨胀操作，此步十分重要，否则由于没有目标周围纹理作为参考，图像填充效果会变得极差。\n",
    "dilate_kernel_size = 50\n",
    "masks1 = [dilate_mask(mask, dilate_kernel_size) for mask in masks]\n",
    "# 对象填充结果可视化\n",
    "text_prompt =\"a teddy bear on a bench\"\n",
    "for idx, mask in enumerate(masks1):\n",
    "    paddle.seed(1234)\n",
    "    img_filled = fill_img_with_sd(img, mask, text_prompt)\n",
    "    plt.imshow( img_filled)\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84808054-e8d5-41c9-8196-d48c0beb1f94",
   "metadata": {},
   "source": [
    "### 2.6 利用mask，实现背景填充（Replace Anything）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8029341-892d-43d9-b048-a3c706ecad51",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.mask_processing import crop_for_filling_pre, crop_for_filling_post\n",
    "from utils.crop_for_replacing import recover_size, resize_and_pad\n",
    "from ppdiffusers import StableDiffusionInpaintPipeline\n",
    "# 利用 StableDiffusionInpaint 实现背景填充\n",
    "def replace_img_with_sd(\n",
    "        img: np.ndarray,\n",
    "        mask: np.ndarray,\n",
    "        text_prompt: str,\n",
    "        step: int = 50,\n",
    "):\n",
    "    # 加载 StableDiffusionInpaint 模型\n",
    "    pipe = StableDiffusionInpaintPipeline.from_pretrained(\"stabilityai/stable-diffusion-2-inpainting\")\n",
    "    # 对img和mask进行预处理（缩放、填充）\n",
    "    img_padded, mask_padded, padding_factors = resize_and_pad(img, mask)\n",
    "    img_padded = pipe(\n",
    "        prompt=text_prompt,\n",
    "        image=Image.fromarray(img_padded),\n",
    "        mask_image=Image.fromarray(255 - mask_padded),\n",
    "        num_inference_steps=step,\n",
    "    ).images[0]\n",
    "    height, width, _ = img.shape\n",
    "    # 将img和mask缩放回原尺寸\n",
    "    img_resized, mask_resized = recover_size(\n",
    "        np.array(img_padded), mask_padded, (height, width), padding_factors)\n",
    "    mask_resized = np.expand_dims(mask_resized, -1) / 255\n",
    "    # 利用缩放后的mask,对生成的背景和原图像前景进行混合\n",
    "    img_resized = img_resized * (1-mask_resized) + img * mask_resized\n",
    "    return img_resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc255ba-5255-4bbb-8538-4adb65eedac0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 对背景填充结果进行可视化\n",
    "masks1 = masks\n",
    "text_prompt=\"sit on the swing\"\n",
    "for idx, mask in enumerate(masks1):\n",
    "    paddle.seed(1234)\n",
    "    img_replaced = replace_img_with_sd(\n",
    "        img, mask, text_prompt)\n",
    "    plt.imshow( img_replaced.astype(np.uint8))\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db464e8a-4ce1-48c4-b037-7d200a16f121",
   "metadata": {},
   "source": [
    "## 三、更多的结果展示\n",
    "\n",
    "### 3.1 Remove Anything\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/d89082c4f58f4cf090698917f86cbf8ddd80e10d3d28413684fdb86ea38d47aa)\n",
    "<!-- <table>\n",
    "  <tr>\n",
    "    <td><img src=\"https://ai-studio-static-online.cdn.bcebos.com/d89082c4f58f4cf090698917f86cbf8ddd80e10d3d28413684fdb86ea38d47aa\" width=\"100%\">  </td>\n",
    "                                                                                                       <td><img src=\"https://ai-studio-static-online.cdn.bcebos.com/d89082c4f58f4cf090698917f86cbf8ddd80e10d3d28413684fdb86ea38d47aa\"  width=\"100%\"></td>\n",
    "    </tr>\n",
    "</table>\n",
    " -->\n",
    " ### 3.2 Remove Angthing Video\n",
    " \n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/63433ba210394e31a9ac5150136aa279c50c6fc678384d24bc320bae3ed90d4d)\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/b0e34a2afc6247b987a214f554726babfd3856ca3b834dcbb126a84f3eecb0c0)\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/f83cdf11c1fc41898d94dd1c5208bdee71ca35fffc1c4fa9a867d642152a7404)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### 3.3 Fill Anything\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/992293257ff04ea792f7123fb292ed9e897ca76fe2b64153b1bbddf93029de90)\n",
    "\n",
    "\n",
    "### 3.4 Replace Anything\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/a8c4df095a6143f9bec36087e2ddb68f34b35686ca464f52a6b665d6c4ff0a36)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970828e6-1d28-47e4-948f-2ba04e82fb86",
   "metadata": {},
   "source": [
    "## 四、部署细节\n",
    "\n",
    "在运行推理代码之前，请确保已经完成 2.1 环境配置中所有代码块的运行。**如果运行了`二、详细说明`中的 2.2-2.6 代码块，请先重启内核，否则会导致显存崩溃。**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1753fb0d-56f0-4b4d-b822-0c622a70375b",
   "metadata": {},
   "source": [
    "### 4.1 Remove Anything\n",
    "\n",
    "根据输入坐标，移除指定对象。示例图像位于/home/aistudio/work/example/remove-anything目录下，points_coords.yaml 记录了每张示例图像的 x，y 坐标，运行脚本时，可以参考上述坐标进行目标移除。使用模型推理时可选的一些参数如下：\n",
    "\n",
    "+ `input_img`:（str）- 输入图像路径。\n",
    "+ `point_coords`:（int, int）-需要移除对象的 x，y 坐标。\n",
    "+ `point_labels`:（int）-需要移除对象的分割标签，默认为1。\n",
    "+ `dilate_kernel_size`:（int）-膨胀核大小，对分割 mask 进行膨胀，不进行该操作，会导致生成图像保留部分原图像痕迹。\n",
    "+ `output_dir`:（str）-生成结果所在目录，默认输出结果保存在 `/home/aistudio/work/results` 目录下。\n",
    "+ `sam_model_type`:（str）-SAM 模型类型，包含 vit_l/vit_b/vit_h 三种，越大的模型分割效果会越好，但是推理速度也越慢，这里  vit_l 模型就已经可以满足项目需求了，且已经保存在 AI studio 数据集中，选用其他模型单独重新下载。\n",
    "+ `lama_config`:（str）-LaMa 模型配置文件路径。\n",
    "+ `lama_ckpt`:（str）-LaMa 模型权重件路径，已经保存在 AI studio 数据集中。\n",
    "+ `predict_config`:（str）-LaMa 模型推理配置文件路径。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b81cf80-500b-4d5d-9de2-1e8cd7a11694",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 显存 7G ,耗时15s\n",
    "%cd /home/aistudio/work/\n",
    "!python remove_anything.py \\\n",
    "    --input_img  /home/aistudio/work/example/remove-anything/cat.jpg \\\n",
    "    --point_coords 600 1100 \\\n",
    "    --point_labels 1 \\\n",
    "    --dilate_kernel_size 15 \\\n",
    "    --output_dir /home/aistudio/work/results \\\n",
    "    --sam_model_type \"vit_l\" \\\n",
    "    --lama_config  /home/aistudio/work/lamn/big_lanm/config.yaml \\\n",
    "    --lama_ckpt /home/aistudio/data/data211468/paddle_gen.pdparams \\\n",
    "    --predict_config /home/aistudio/work/lamn/config/default.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5b44c6-9e3b-4b29-8ad9-0748d4bc8174",
   "metadata": {},
   "source": [
    "### 4.2 Remove Anything Video\n",
    "\n",
    "根据移除对象的类型，移除视频中的指定对象。示例视频位于 /home/aistudio/work/example/remove-anything-video 目录下，remove_type.yaml 记录了每个示例视频的移除对象，运行脚本时，可以参考上述移除类别进行视频对象移除。需要注意的是如果视频中的目标过大或背景比较复杂会导致移除效果较差，且移除对象的类别需要在 COCO 80类中（检测器是在COCO数据集进行训练的），使用模型推理时可选的一些参数如下：\n",
    "\n",
    "+ `input_video`:（str）- 输入视频的路径。\n",
    "+ `remove_type`:（str）-移除对象的类别。\n",
    "+ `dilate_kernel_size`:（int）-膨胀核大小，对分割 mask 进行膨胀，不进行该操作，会导致生成视频保留部分原图像痕迹。\n",
    "+ `output_dir`:（str）-生成结果所在目录，默认输出结果保存在 `/home/aistudio/work/results` 目录下。\n",
    "+ `sam_model_type`:（str）-SAM 模型类型，包含 vit_l/vit_b/vit_h 三种，越大的模型分割效果会越好，但是推理速度也越慢，这里  vit_l 模型就已经可以满足项目需求了，且已经保存在 AI studio 数据集中，选用其他模型单独重新下载。\n",
    "+ `lama_config`:（str）-LaMa 模型配置文件路径。\n",
    "+ `lama_ckpt`:（str）-LaMa 模型权重件路径，已经保存在 AI studio 数据集中。\n",
    "+ `predict_config`:（str）-LaMa 模型推理配置文件路径。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c87d1e8-c3e9-4c6e-ba9e-7a100f60bd07",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 显存 7.2 G, 耗时 30 s\n",
    "%cd /home/aistudio/work/\n",
    "!python remove_anything_video.py \\\n",
    "    --input_video /home/aistudio/work/example/remove-anything-video/car.mp4 \\\n",
    "    --remove_type \"car\"\\\n",
    "    --dilate_kernel_size 15 \\\n",
    "    --output_dir /home/aistudio/work/results \\\n",
    "    --sam_model_type \"vit_l\" \\\n",
    "    --lama_config  /home/aistudio/work/lamn/big_lanm/config.yaml \\\n",
    "    --lama_ckpt /home/aistudio/data/data211468/paddle_gen.pdparams \\\n",
    "    --predict_config /home/aistudio/work/lamn/config/default.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7849190f-98ea-403c-afee-8c9cf3245f33",
   "metadata": {},
   "source": [
    "### 4.3 Fill Anything\n",
    "\n",
    "根据输入坐标和文本提示填充指定对象。示例图像位于/home/aistudio/work/example/fill-anything目录下，points_coords.yaml 记录了每张示例图像的 x，y 坐标，text_prompt.yaml 记录每张示例图像的文本提示，运行脚本时，可以参考上述坐标和文本提示进行对象填充。使用模型推理时可选的一些参数如下：\n",
    "\n",
    "+ `input_img`:（str）- 输入图像路径。\n",
    "+ `point_coords`:（int, int）-需要填充对象的 x，y 坐标。\n",
    "+ `point_labels`:（int）-需要填充对象的分割标签，默认为1。\n",
    "+ `text_prompt`:（str）-用于指导填充对象生成的文本提示。\n",
    "+ `dilate_kernel_size`:（int）-膨胀核大小，对分割 mask 进行膨胀，不进行该操作，会导致生成图像保留部分原图像痕迹。\n",
    "+ `output_dir`:（str）-生成结果所在目录，默认输出结果保存在 `/home/aistudio/work/results` 目录下。\n",
    "+ `sam_model_type`:（str）-SAM 模型类型，包含 vit_l/vit_b/vit_h 三种，越大的模型分割效果会越好，但是推理速度也越慢，这里  vit_l 模型就已经可以满足项目需求了，且已经保存在 AI studio 数据集中，选用其他模型单独重新下载。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d09f4e-cf66-414c-afad-30107f6ca90f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%cd /home/aistudio/work/\n",
    "# 9.1GB 显存，耗时 81s\n",
    "!python fill_anything.py \\\n",
    "    --input_img /home/aistudio/work/example/fill-anything/sample5.png\\\n",
    "    --point_coords 627 845\\\n",
    "    --point_labels 1 \\\n",
    "    --text_prompt \"a Picasso painting on the wall\" \\\n",
    "    --dilate_kernel_size 50 \\\n",
    "    --output_dir /home/aistudio/work/results \\\n",
    "    --sam_model_type \"vit_l\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92cfc2d9-aa28-4efa-8f2d-c639bdc96e9e",
   "metadata": {},
   "source": [
    "### 4.4 Replace Anything\n",
    "\n",
    "\n",
    "根据输入坐标和文本提示，替换指定对象的背景。示例图像位于/home/aistudio/work/example/replace-anything目录下，points_coords.yaml 记录了每张示例图像的 x，y 坐标，text_prompt.yaml 记录了每张示例图像的文本提示，运行脚本时，可以参考上述坐标和文本提示进行背景替换。使用模型推理时可选的一些参数如下：\n",
    "\n",
    "+ `input_img`:（str）-输入图像路径。\n",
    "+ `point_coords`:（int, int）-需要填充对象的 x，y 坐标。\n",
    "+ `point_labels`:（int）-需要填充对象的分割标签，默认为1。\n",
    "+ `text_prompt`:（str）-用于指导填充背景生成的文本提示。\n",
    "+ `output_dir`:（str）-生成结果所在目录，默认输出结果保存在 `/home/aistudio/work/results` 目录下。\n",
    "+ `sam_model_type`:（str）-SAM 模型类型，包含 vit_l/vit_b/vit_h 三种，越大的模型分割效果会越好，但是推理速度也越慢，这里  vit_l 模型就已经可以满足项目需求了，且已经保存在 AI studio 数据集中，选用其他模型单独重新下载。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18363bf9-e583-4cde-91f0-9ec094b9fb6c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 显存为 9G 左右，耗时 80 s 左右\n",
    "%cd /home/aistudio/work/\n",
    "!python replace_anything.py \\\n",
    "    --input_img /home/aistudio/work/example/replace-anything/dog.png \\\n",
    "    --point_coords 750 500 \\\n",
    "    --point_labels 1 \\\n",
    "    --text_prompt \"sit on the swing\" \\\n",
    "    --output_dir  /home/aistudio/work/results \\\n",
    "    --sam_model_type \"vit_l\" \\"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab88f950-6abf-49aa-ae00-e6fa08003b8b",
   "metadata": {},
   "source": [
    "## 五、总结\n",
    "\n",
    "该项目对 LaMa 模型的推理部分进行了复现，并结合 paddleseg 中的 SAM 模型和 ppdiffuser 中的 stable diffusion inpaint 模型，实现 Inpaint Anything 中 Remove Anything、Fill Anything 和 Replace Anything 图像编辑模式。利用这三种模式，用户可以生成一些有趣的图片。此外，本人还基于图像级的 Inpaint Anything 和 PPYOLOE 在COCO数据集上的训练模型 实现了特定类别的视频对象移除。本人下一步计划是实现一个低配版的 Wonder Studio AI 视频特效项目。\n",
    "\n",
    "图像编辑和视频编辑是一件十分有趣的事情。 Inpaint Anything 的Paddle 实现代码已经上传到 Github 上， repo地址为：，欢迎大家参与到项目建设中。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dac6c5b-fd3a-48a1-a8da-96f70283e4e6",
   "metadata": {},
   "source": [
    "## 参考项目：\n",
    "\n",
    "【1】 [Inpaint Anything: Segment Anything Meets Image Inpainting](https://github.com/geekyutao/Inpaint-Anything)\n",
    "\n",
    "【2】 [Segment Anything with PaddleSeg](https://github.com/PaddlePaddle/PaddleSeg/tree/release/2.8/contrib/SegmentAnything)\n",
    "\n",
    "【3】 [PPDiffusers: Diffusers toolbox implemented based on PaddlePaddle](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/ppdiffusers)\n",
    "\n",
    "【4】[Omnimatte in PyTorch](https://github.com/erikalu/omnimatte)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
